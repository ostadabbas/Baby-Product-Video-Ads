


import pickle
import os
import tqdm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.api import OLS
import statsmodels.api as sm
import statsmodels.stats as sts
from scipy import stats
import statsmodels.stats.api as sms


import datetime
date = datetime.datetime.now()
date = date.strftime("%Y.%m.%d")
np.random.seed(0)

def stdz(series: pd.Series):
    """Standardize the given pandas Series"""
    return (series - series.mean())/series.std()
def unitstdz(series:pd.Series):
    return (series - series.min())/(series.max()-series.min())

from imblearn.under_sampling import RandomUnderSampler

import re
def extract_video_number(filename):
    match = re.match(r'(\d+)[+-]', filename)
    return match.group(1) if match else None





rating = pd.read_excel('../dataset/eyetracking-coordinates-imname.xlsx', sheet_name='video-based')


rating.columns


rating.drop('Shotvariance',axis=1,inplace=True)


features = pd.read_csv('../dataset/infant_ads_visual_features.csv')


features.head()


features.columns


data = features.merge(rating, on='VideoNumber', how='inner')


len(data)


data.tail()


for col in data.columns:
    if data[col].isna().any():
        print(col)


data = data.dropna(how='any')
data = data.replace([np.inf, -np.inf], np.nan).dropna()


features = ['color_brightness_mean',
       'color_brightness_std', 'color_hue_mean', 'color_hue_std',
       'color_saturation_mean', 'color_saturation_std',
       'color_brightness_contrast_mean', 'color_brightness_contrast_std',
       'color_color_diversity_mean', 'color_color_diversity_std',
       'color_clarity_mean', 'color_clarity_std', 'color_black_mean',
       'color_black_std', 'color_blue_mean', 'color_blue_std',
       'color_brown_mean', 'color_brown_std', 'color_gray_mean',
       'color_gray_std', 'color_green_mean', 'color_green_std',
       'color_orange_mean', 'color_orange_std', 'color_pink_mean',
       'color_pink_std', 'color_purple_mean', 'color_purple_std',
       'color_red_mean', 'color_red_std', 'color_white_mean',
       'color_white_std', 'color_yellow_mean', 'color_yellow_std',
       'texture_c1_contrast_mean', 'texture_c1_contrast_std',
       'texture_c1_correlation_mean', 'texture_c1_correlation_std',
       'texture_c1_energy_mean', 'texture_c1_energy_std',
       'texture_c1_homogeneity_mean', 'texture_c1_homogeneity_std',
       'texture_c1_dissimilarity_mean', 'texture_c1_dissimilarity_std',
       'texture_c2_contrast_mean', 'texture_c2_contrast_std',
       'texture_c2_correlation_mean', 'texture_c2_correlation_std',
       'texture_c2_energy_mean', 'texture_c2_energy_std',
       'texture_c2_homogeneity_mean', 'texture_c2_homogeneity_std',
       'texture_c2_dissimilarity_mean', 'texture_c2_dissimilarity_std',
       'texture_c3_contrast_mean', 'texture_c3_contrast_std',
       'texture_c3_correlation_mean', 'texture_c3_correlation_std',
       'texture_c3_energy_mean', 'texture_c3_energy_std',
       'texture_c3_homogeneity_mean', 'texture_c3_homogeneity_std',
       'texture_c3_dissimilarity_mean', 'texture_c3_dissimilarity_std',
        'inner_brightness_mean',
       'inner_brightness_std', 'inner_sharpness_mean', 'inner_sharpness_std',
       'objects_count_yolo_mean', 'objects_count_yolo_std',
       'face_count_yolo_mean', 'face_count_yolo_std', 'region_size_avg_mean',
       'region_size_avg_std', 'region_count_mean', 'region_count_std',
       'rule_of_thirds_mean', 'rule_of_thirds_std']


len(features)





data.head()


dispersion1 = pd.read_json('dispersion_measure0629.json', lines=True)


dispersion1['VideoNumber'] = dispersion1['ad_id'].apply(extract_video_number)
data['VideoNumber'] = data['VideoNumber'].astype(int)
dispersion1['VideoNumber'] = dispersion1['VideoNumber'].astype(int)
data = data.merge(dispersion1[['id', 'std_x', 'std_y', 'combined_std', 'convex_hull_area',
       'convex_hull_area_shapely', 'mean_euclidean_distance', 'VideoNumber']], on='VideoNumber')


data.head(10)


len(data)


data = data.dropna()


len(data)





from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

X = data[features]
y = data['convex_hull_area']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)



from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV






# Apply PCA
pca = PCA()
X_pca = pca.fit_transform(X_scaled)

# Get explained variance ratios
explained_var_ratio = pca.explained_variance_ratio_

# Determine number of components to keep
total_var = 0
n_components = 0
for i, ratio in enumerate(explained_var_ratio):
    total_var += ratio
    if total_var >= 0.975:  # Adjust the threshold as needed
        n_components = i + 1
        break

print(f"Number of principal components selected: {n_components}")

# Apply PCA transformation with selected components
pca_final = PCA(n_components=n_components)
X_selected = pca_final.fit_transform(X_scaled)

# Get selected features (if needed, you can interpret the components to understand which original features contribute the most)
selected_features = X.columns[pca_final.components_.mean(axis=0).argsort()[::-1][:n_components]]
print("Selected features by PCA:", selected_features)


sorted_values = np.sort(selected_features.values)
sorted_values


data['preference'] = data['GroupN(1=low(1-3),2=neutral(4-6),3=high(7-10))']


conditions = [
    (0 < data['PurchaseDesireMean']) & (data['PurchaseDesireMean'] <= 3),
    (3 < data['PurchaseDesireMean']) & (data['PurchaseDesireMean'] <= 6),
    (6 < data['PurchaseDesireMean']) & (data['PurchaseDesireMean'] <= 10)
]

choices = [1, 2, 3]

data['purchase'] = np.select(conditions, choices)






